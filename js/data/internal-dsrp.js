var mod = angular.module("internalDsrpMod", []);

mod.controller("internalDsrpCtrl", ["$scope", '$sce', function($scope, $sce) {

    var DIR = 'images/dsrp/'

    $scope.projects = [
        {
            title: "Developing an integrative probabilistic network model of LINCS readouts of cellular states",
            text: $sce.trustAsHtml("A regulatory network model (REM) defines a set of signaling proteins, transcription factors and their interactions that lead to the induction of a specific transcriptional response to perturbation (TRP). The REM integrates the signaling network and transcriptional regulatory network into a single regulatory network model. The goal of this DSR project is to develop methods for explaining the transcriptional response to perturbation (TRP) in terms of regulatory network activity. Our assumption is that virtually all perturbations studied by LINCS will be characterized by a high-dimensional transcriptional readout. A substantial portion of perturbations will also be characterized by various proteomic and phosphoprotemic assays providing direct activity readouts of regulatory proteins. Information sources and datasets outside of LINCS will provide information about the protein-protein interaction network that defines the topology of the regulatory network. Such information is partially embedded with pathway and protein interaction databases such as STRING, NCI PID, KEGG, and HPRD; activity of regulatory nodes, for example, transcription factors profiled by ENCODE; drug targets, such as those listed in DrgBank, STITCH, or PubChem. Computational modeling will add information about the protein-pertrubagen interactions. Our objective is to derive conceptual and integrative probabilistic model for leveraging all relevant data and information to assess Mode of Action (MOA) of perturbagens by inferring their regulatory network. During the initial funding period we have been addressing the following aspects of the regulatory network model development: Conceptual organization of currently available and future data types and datasets to be generated by the LINCS DSGCs. This activity is assessing the type of information that different assays and datasets will provide about the REM and the combinations of different types of data that will be available to characterize MOA of a specific perturbagen; and development of the integrative probabilistic model in the form of a non-stationary Bayesian graph kernel (BGK) model. The modeling strategy will proceed by defining the formal prior probability distributions based on all information about various components of the BGK and assess the likelihood of activities of individual nodes following traditional Bayesian learning principles. We are systematically building an integrated information resource that will organize all information relevant to the REM. This includes gathering relevant non-LINCS data and open-source tools for managing and computing with such data and resources. Computational modeling tools range from R packages for computing with graphs, graph kernel modeling, representation of BioPAX objects, and more, to integrate with our own software development efforts aimed at regulatory network modeling."),
            image: DIR + 'fig1.png',
            caption: 'Fig. 1 the conceptual outline of the integrated Regulatory Network Modeling strategy. A) The regulatory network model integrates signaling and expression regulatory networks whose activity explains the TRP; B) The data and information sources about activity of regulatory nodes in the network is gathered and transformed into activity scores for all nodes in the network. C) Integrated probabilistic model (BGK) is use to integrate all relevant information and data. The classical Bayesian learning strategy in the form of posterior probability distribution of node activities is used to identify active network nodes.'
        },
        {
            title: 'Community Science Project to Link Drugs, Targets and Diseases from Expression Signatures',
            text: $sce.trustAsHtml('<p>Genome-wide gene expression profiling before and after single gene perturbation in disease models can potentially be used to identify novel drug targets. However, collecting expression data after perturbing all genes in many disease models is not feasible. Here we present a community science project that attempts to identify drugs and drug targets for many diseases in an alternative way. The project recruited over 100 participants who together extract gene expression signatures from the Gene Expression Omnibus (GEO) from three types of studies: 1) where mammalian cells were perturbed by knockdown, knockout or mutation of a single gene; 2) where diseased tissue was compared to normal tissue; and 3) where gene expression was measured before and after drug treatment. The collection of these drug and single gene perturbation expression signatures is queried against the expression signatures from the human diseases. The goal is to find gene and drug perturbations that were significantly opposite from the disease signatures to predict potential drugs and targets for many diseases. Significant similar signatures can suggest gene loss-of-function as disease mechanisms, as well as predict side-effects for drugs. The collective resource is open-source and delivered as a Shiny web-based application. With this Shiny app users can query their own data against the community extracted signatures, browser predicted novel target-disease and drug-disease associations, as well as continually contribute to this growing resource.</p><p><em>A paper describing the project is currently under preparation.</em></p>'),
            image: DIR + 'fig2.png',
            caption: 'Fig. 2 Screenshot from the BD2K-LINCS DCIC microtask leaderboard to extract gene expression signatures from GEO were a single human gene was either knocked down or knocked out. The top student, Caroline Dias Monteiro, is from Brazil and is planning to apply to a PhD program in the field of Big Data and systems biology.'
        },
        {
            title: 'Dynamics of the Discovery Process of Protein-Protein Interactions from Low Content Studies',
            text: $sce.trustAsHtml('<p>Thousands of biological and biomedical investigators study of the functional role of single genes and their protein products in normal physiology and in disease. The findings from these studies are reported in research articles that stimulate new research. It is now established that a complex regulatory network is controlling human cellular fate, and this community of researchers are continually unraveling this network. Attempts to integrate results from such accumulated knowledge resulted in literature-based protein-protein interaction network (PPIN) and pathway databases. These databases are widely used by the community to analyze new data collected from emerging genome-wide studies with the assumption that the data within these literature-based databases is the ground truth and contain no biases. While suspicion for research focus biases is growing, a concrete proof for it is still missing. It is difficult to prove because the real PPIN is mostly unknown.  We analyzed the longitudinal discovery process of literature-based mammalian and yeast PPINs to observe that these networks are discovered non-uniformly. The pattern of discovery is related to a theoretical concept proposed by Kauffman called “expanding the adjacent possible”. We introduce a network discovery model which explicitly includes the space of possibilities in the form of a true underlying PPIN. <span class="underline">Our model strongly suggests that research focus bias exists in the observed discovery dynamics of these networks</span>. In summary, more care should be placed when using PPIN databases for analysis of newly acquired data, and when considering prior knowledge when designing new experiments.</p><p><em>A paper describing the project was published in BMC Systems Biology: <a href="http://www.biomedcentral.com/1752-0509/9/26/abstract" target="_blank">http://www.biomedcentral.com/1752-0509/9/26/abstract</a></em></p>')
        },
        {
            title: 'Principal Angle Enrichment Analysis (PAEA): a geometrical approach to gene set enrichment',
            text: $sce.trustAsHtml('<p>Functional analysis of differential expression is central to genome-wide profiling of biological samples. We developed a new multivariate approach to gene-set enrichment called, Principal Angle Enrichment Analysis (PAEA). The approach we developed characterizes the differential expression with a single direction in expression space and this forms the basis for the gene-level statistics. At the gene-set level, PAEA uses the geometrical concept of the principal angle to quantify the enrichment. We find that PAEA outperforms a selection of commonly used gene set enrichment methods in the setting of expression profiling under transcription factor perturbation using a library of gene sets based on ChIP-Seq data from 482 studies. We also found that PAEA was able to infer the significance of aging-related phenotype terms from a collection of gene expression profiling studies where tissue from young adults was compared to tissue of elderly subjects. Furthermore, we analyzed five gene expression studies comparing diseased to normal samples in conjunction with the MGI human disease vocabulary. We found that only PAEA was able to significantly prioritize the appropriate disease. PAEA provides a new approach to gene-set enrichment which improves the prioritization of gene-sets and provides a clearer picture of the relevant biological terms.</p><p><em>A web based system that implements PAEA using Shiny is available from: <a href="http://amp.pharm.mssm.edu/PAEA " target="_blank">http://amp.pharm.mssm.edu/PAEA </a></em></p>')
        },
        {
            title: 'Assessing the Global Dimensionality of LINCS Signatures',
            text: $sce.trustAsHtml('Genome-wide transcriptional or proteomics profiles can be represented as points in gene-expression space. The expression level of each gene or protein can be regarded as a coordinate in this space. Natural biological variability across many samples means that each biological state, e.g. a specific cell type under a specific condition, is associated with a cloud of points in a particular expression space rather than a single point, the dimensionality of this cloud is one way to characterize a biological state. Because genes and proteins are connected in a complex network of interactions, there is informative structure in the patterns of biological variation; we are developing methods to evaluate the dimensionality of such structure in high-dimensional high-throughput data. We can estimate the dimensionality of data sets using fast linear methods with only a moderate number of expression profile samples by extrapolating the number of principal components required to capture a given (large) fraction of the variance. This serves two purposes, first the principal components analysis serves as a smoothing filter that separates biological from technical variation, and secondly it provides an estimate of the dimensionality of the smoothed data. Crucially, the extrapolation procedure allows an estimate of the overall dimensionality of the data to be made with a sample size which is smaller than the dimensions of the data; it is this that makes this method feasible for genome-scale biological data. Furthermore, when sample sizes are large enough to resolve non-linear structures, this method can be generalized by the use of regularized and cross-validated non-linear basis expansions. Evaluating the dimensions of data sets provides insights into the systems-level dynamics underlying the variations in transcriptional and proteomics data and also aids with various statistical analyses. By identifying representations of the data in its lowest dimensional form, we can improve the power of statistical analyses, reduce the burden of storage of large data sets, and improve interpretability.')
        }
    ];
}]);
